{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "\n",
    "\n",
    "#Creating RDD that contains all rows of CSV file except Header\n",
    "csvf=sc.textFile(\"CategoryNormalized.csv\")\\\n",
    "        .filter(lambda x: 'prev' not in x)\\\n",
    "        .map(lambda x:x.encode('ascii').split(','))\n",
    "        #.map(Convert)\n",
    "\n",
    "        \n",
    "# Creating Header using first line of csv file\n",
    "Header=sc.textFile(\"CategoryNormalized.csv\").map(lambda x:x.encode('ascii').split(',')).first()\n",
    "#csvf.take(3)\n",
    "CV_data = sqlCtx.createDataFrame(csvf,Header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def labelData(data):\n",
    "    data=data.rdd\n",
    "    # label: row[end], features: row[0:end-1]\n",
    "    return data.map(lambda row: LabeledPoint(row[-1], row[0:-1]))\n",
    "\n",
    "training_data, testing_data = labelData(CV_data).randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We are calling labeldata function that is defined in decision tree model that will submit data for percentage split\n",
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "# Load and parse the data file into an RDD of LabeledPoint.\n",
    "#RFdata = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')\n",
    "\n",
    "\n",
    "def labelData(data):\n",
    "    data=data.rdd\n",
    "    # label: row[end], features: row[0:end-1]\n",
    "    return data.map(lambda row: LabeledPoint(row[-1], row[0:-1]))\n",
    "\n",
    "\n",
    "# Split the data into training and test sets (20% held out for testing)\n",
    "\n",
    "RFtraining_data, RFtesting_data = labelData(CV_data).randomSplit([0.8, 0.2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train = 0.941921363246\n",
      "Accuracy of Test = 0.877867002572\n"
     ]
    }
   ],
   "source": [
    "#RandomForest Model training\n",
    "RFmodel = RandomForest.trainClassifier(RFtraining_data, numClasses=3, categoricalFeaturesInfo={},\n",
    "                                     numTrees=15, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth=17, maxBins=32)\n",
    "\n",
    "# Evaluate model on test instances and compute test error\n",
    "predictions = RFmodel.predict(RFtesting_data.map(lambda x: x.features))\n",
    "\n",
    "labelsAndPredictions = RFtesting_data.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(lambda (v, p): v != p).count() / float(RFtesting_data.count())\n",
    "#print('Accuracy of Test = ' + str(1-testErr))\n",
    "\n",
    "Trainpredictions = RFmodel.predict(RFtraining_data.map(lambda x: x.features))\n",
    "TrlabelsAndPredictions = RFtraining_data.map(lambda lp: lp.label).zip(Trainpredictions)\n",
    "trainErr = TrlabelsAndPredictions.filter(lambda (v, p): v != p).count() / float(RFtraining_data.count())\n",
    "\n",
    "labelsAndPredictions\n",
    "\n",
    "print('Accuracy of Train = ' + str(1-trainErr))\n",
    "print('Accuracy of Test = ' + str(1-testErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "F-1 Score          0.941921363246\n",
      "Confusion Matrix\n",
      "[[ 23353.    954.    433.]\n",
      " [   710.  26112.   1397.]\n",
      " [   166.    798.  22835.]]\n",
      "\n",
      "\n",
      "Test Set\n",
      "F-1 Score          0.877867002572\n",
      "Confusion Matrix\n",
      "[[ 5508.   466.   132.]\n",
      " [  558.  5729.   746.]\n",
      " [   91.   334.  5489.]]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "def getPredictionsLabels(RFmodel, RFtesting_data):\n",
    "    predictions = RFmodel.predict(RFtesting_data.map(lambda r: r.features))\n",
    "    return predictions.zip(RFtesting_data.map(lambda r: r.label))\n",
    "\n",
    "def printMetrics(predictions_and_labels):\n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    print 'F-1 Score         ', metrics.fMeasure()\n",
    "    #print 'F Score         ', metrics.fMeasureByThreshold()\n",
    "    print 'Confusion Matrix\\n', metrics.confusionMatrix().toArray()\n",
    "\n",
    "#Printing F1 Score and Confusion Matrix\n",
    "print('Training Set')\n",
    "training_labels = getPredictionsLabels(RFmodel, RFtraining_data)\n",
    "printMetrics(training_labels)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print ('Test Set')\n",
    "predictions_and_labels = getPredictionsLabels(RFmodel, RFtesting_data)\n",
    "printMetrics(predictions_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set\n",
      "F-1 Score          0.894007471069\n",
      "Confusion Matrix\n",
      "[[ 22791.   1086.    831.]\n",
      " [  1837.  23671.   2530.]\n",
      " [   540.   1291.  21985.]]\n",
      "\n",
      "\n",
      "Test Set\n",
      "F-1 Score          0.843524338927\n",
      "Confusion Matrix\n",
      "[[ 5368.   516.   254.]\n",
      " [  822.  5531.   861.]\n",
      " [  143.   416.  5338.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#                       Decision Tree Classifier Starts Here\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "\n",
    "def labelData(data):\n",
    "    data=data.rdd\n",
    "    # label: row[end], features: row[0:end-1]\n",
    "    return data.map(lambda row: LabeledPoint(row[-1], row[:-1]))\n",
    "\n",
    "#Splitting the Data into Training and Test Set\n",
    "training_data, testing_data = labelData(CV_data).randomSplit([0.8, 0.2])\n",
    "\n",
    "#Building The Decision tree Classifier Model\n",
    "model = DecisionTree.trainClassifier(training_data, numClasses=3, maxDepth=17,\n",
    "                                     categoricalFeaturesInfo={},\n",
    "                                     impurity='gini', maxBins=32)\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "def getPredictionsLabels(model, test_data):\n",
    "    predictions = model.predict(test_data.map(lambda r: r.features))\n",
    "    return predictions.zip(test_data.map(lambda r: r.label))\n",
    "\n",
    "def printMetrics(predictions_and_labels):\n",
    "    metrics = MulticlassMetrics(predictions_and_labels)\n",
    "    print 'F-1 Score         ', metrics.fMeasure()\n",
    "    #print 'F Score         ', metrics.fMeasureByThreshold()\n",
    "    print 'Confusion Matrix\\n', metrics.confusionMatrix().toArray()\n",
    "\n",
    "#Printing F1 Score and Confusion Matrix\n",
    "print('Training Set')\n",
    "training_labels = getPredictionsLabels(model, training_data)\n",
    "printMetrics(training_labels)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print ('Test Set')\n",
    "predictions_and_labels = getPredictionsLabels(model, testing_data)\n",
    "printMetrics(predictions_and_labels)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
